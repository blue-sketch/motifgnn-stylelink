{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/k0zd3Tb1NNlXJS4T5jTh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blue-sketch/motifgnn-stylelink/blob/main/mgnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load Data\n",
        "df = pd.read_csv('user_features.csv')\n",
        "\n",
        "# 2. Extract and Normalize Features\n",
        "# Drop user_id to get just the 387 features\n",
        "feature_data = df.drop(columns=['user_id']).values\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(feature_data)\n",
        "x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
        "\n",
        "# 3. Define StyleLink Encoder (The \"Vibe\" Compressor)\n",
        "# Input: 387 dims -> Output: 64 dims\n",
        "class StyleLinkEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),  # Stabilizes values\n",
        "            nn.ReLU()                    # Adds non-linearity\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "# 4. Generate the Vectors\n",
        "# Initialize the layer (random weights for now, before training)\n",
        "input_dim = x_tensor.shape[1]\n",
        "model = StyleLinkEncoder(input_dim, 64)\n",
        "model.eval() # Set to eval mode for inference\n",
        "\n",
        "with torch.no_grad():\n",
        "    vibe_vectors = model(x_tensor)\n",
        "\n",
        "# 5. Show results\n",
        "print(f\"Input Shape: {x_tensor.shape}\")\n",
        "print(f\"Output 'Vibe Vector' Shape: {vibe_vectors.shape}\")\n",
        "print(\"\\nFirst User's Vibe Vector (First 10 values):\")\n",
        "print(vibe_vectors[0][:10])\n",
        "\n",
        "# Create a dataframe for display\n",
        "vibe_df = pd.DataFrame(vibe_vectors.numpy(), columns=[f'vibe_{i}' for i in range(64)])\n",
        "vibe_df.insert(0, 'user_id', df['user_id'])\n",
        "print(\"\\nPreview of the 64-dimensional vectors:\")\n",
        "print(vibe_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8SzQ1K64TnK",
        "outputId": "fce4b0de-9c89-46e2-fe81-daca988a0b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: torch.Size([388, 387])\n",
            "Output 'Vibe Vector' Shape: torch.Size([388, 64])\n",
            "\n",
            "First User's Vibe Vector (First 10 values):\n",
            "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6950, 1.0652, 0.2325,\n",
            "        0.9271])\n",
            "\n",
            "Preview of the 64-dimensional vectors:\n",
            "   user_id    vibe_0    vibe_1    vibe_2    vibe_3    vibe_4    vibe_5  \\\n",
            "0       19  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1       58  0.000000  0.352296  0.000000  0.715390  0.822862  0.252960   \n",
            "2       60  0.000000  0.000000  0.647893  1.498623  0.672642  0.000000   \n",
            "3       76  0.313097  0.000000  0.561914  0.000000  0.076767  0.000000   \n",
            "4      101  0.548518  0.079172  1.001337  0.000000  0.000000  0.909625   \n",
            "\n",
            "     vibe_6    vibe_7    vibe_8  ...   vibe_54   vibe_55   vibe_56   vibe_57  \\\n",
            "0  0.694984  1.065150  0.232513  ...  0.000000  0.138096  0.839219  0.000000   \n",
            "1  0.011015  1.045413  0.000000  ...  0.000000  0.000000  0.000000  0.495057   \n",
            "2  0.000000  0.000000  0.000000  ...  0.000000  0.123875  0.308274  0.418766   \n",
            "3  0.166582  0.142734  1.664339  ...  0.317961  0.930191  0.308547  0.324576   \n",
            "4  0.339109  0.244742  0.546470  ...  0.000000  0.151658  1.417799  0.000000   \n",
            "\n",
            "    vibe_58   vibe_59   vibe_60   vibe_61   vibe_62   vibe_63  \n",
            "0  0.579772  0.164904  0.000000  0.143487  1.514581  0.000000  \n",
            "1  0.219410  0.000000  0.233886  0.760007  0.431938  0.000000  \n",
            "2  0.421190  0.000000  0.000000  1.238812  0.449620  0.000000  \n",
            "3  0.782176  1.206706  0.000000  0.378713  0.241050  0.000000  \n",
            "4  0.590374  0.000000  0.000000  0.000000  0.000000  0.138441  \n",
            "\n",
            "[5 rows x 65 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"üèóÔ∏è Building the VibeMatch Graph...\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 1: RE-GENERATE VIBE VECTORS (64-DIM)\n",
        "# ==========================================\n",
        "# (We re-run this to ensure variables are fresh)\n",
        "df_features = pd.read_csv('user_features.csv')\n",
        "raw_x = df_features.drop(columns=['user_id', 'mapped_id'], errors='ignore').values\n",
        "\n",
        "# Normalize\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(raw_x)\n",
        "x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
        "\n",
        "# Run StyleLink Encoder\n",
        "class StyleLink(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "style_model = StyleLink(387, 64)\n",
        "with torch.no_grad():\n",
        "    vibe_vectors = style_model(x_tensor)\n",
        "\n",
        "print(f\"‚úÖ Nodes Ready: {vibe_vectors.shape[0]} Users with {vibe_vectors.shape[1]}-dim Vibe Vectors.\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 2: MAP INTERACTIONS TO NODES\n",
        "# ==========================================\n",
        "df_interactions = pd.read_csv('interactions_final.csv')\n",
        "\n",
        "# create map: {User_ID -> Index 0..N}\n",
        "unique_users = df_features['user_id'].unique()\n",
        "user_map = {uid: i for i, uid in enumerate(unique_users)}\n",
        "\n",
        "# Filter & Map Edges\n",
        "valid_edges = df_interactions[\n",
        "    df_interactions['source'].isin(user_map) &\n",
        "    df_interactions['target'].isin(user_map)\n",
        "].copy()\n",
        "\n",
        "source_idx = valid_edges['source'].map(user_map).values\n",
        "target_idx = valid_edges['target'].map(user_map).values\n",
        "\n",
        "edge_index = torch.tensor([source_idx, target_idx], dtype=torch.long)\n",
        "\n",
        "print(f\"‚úÖ Edges Ready: {edge_index.shape[1]} Interactions mapped.\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 3: CREATE THE FINAL GRAPH OBJECT\n",
        "# ==========================================\n",
        "vibe_graph = Data(x=vibe_vectors, edge_index=edge_index)\n",
        "\n",
        "print(\"\\n=== üéØ VibeMatch Graph Object ===\")\n",
        "print(vibe_graph)\n",
        "print(\"-------------------------------\")\n",
        "print(f\"1. x (Features): {vibe_graph.x.shape}  <-- This is your StyleLink Output\")\n",
        "print(f\"2. edge_index:   {vibe_graph.edge_index.shape}  <-- This is your MGNN Input\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEA3vzRo4uHP",
        "outputId": "0e5a4f74-194b-47a1-85e3-797b82cdb650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèóÔ∏è Building the VibeMatch Graph...\n",
            "‚úÖ Nodes Ready: 388 Users with 64-dim Vibe Vectors.\n",
            "‚úÖ Edges Ready: 1585 Interactions mapped.\n",
            "\n",
            "=== üéØ VibeMatch Graph Object ===\n",
            "Data(x=[388, 64], edge_index=[2, 1585])\n",
            "-------------------------------\n",
            "1. x (Features): torch.Size([388, 64])  <-- This is your StyleLink Output\n",
            "2. edge_index:   torch.Size([2, 1585])  <-- This is your MGNN Input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import to_undirected, negative_sampling, add_self_loops\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP & SAFETY CHECKS\n",
        "# ==========================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üöÄ Setting up on {device}...\")\n",
        "\n",
        "# Check inputs from the previous step\n",
        "if torch.isnan(vibe_graph.x).any():\n",
        "    print(\"‚ö†Ô∏è Warning: NaNs found in Input Features! Fixing them...\")\n",
        "    vibe_graph.x = torch.nan_to_num(vibe_graph.x, nan=0.0)\n",
        "\n",
        "# Move data to GPU\n",
        "x = vibe_graph.x.to(device)\n",
        "edge_index = vibe_graph.edge_index.to(device)\n",
        "\n",
        "# ==========================================\n",
        "# 2. GENERATE MOTIFS (Structure Views)\n",
        "# ==========================================\n",
        "def get_dual_motifs(edge_index, num_nodes):\n",
        "    # Ensure every node has at least one connection (Self-loop) to prevent NaN in GCN\n",
        "    edge_index_safe, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
        "\n",
        "    row, col = edge_index\n",
        "\n",
        "    # Motif A: Reciprocal Matches (The \"Dating\" Signal)\n",
        "    edge_set = set(zip(row.tolist(), col.tolist()))\n",
        "    recip_edges = [[u, v] for u, v in edge_set if (v, u) in edge_set]\n",
        "\n",
        "    if len(recip_edges) > 0:\n",
        "        motif_recip = torch.tensor(recip_edges, dtype=torch.long).t().to(device)\n",
        "    else:\n",
        "        motif_recip = torch.empty((2, 0), dtype=torch.long).to(device)\n",
        "\n",
        "    # Motif B: Clusters (The \"Community\" Signal)\n",
        "    motif_cluster = to_undirected(edge_index_safe).to(device)\n",
        "\n",
        "    return [motif_recip, motif_cluster]\n",
        "\n",
        "# Split Train/Test\n",
        "mask = torch.rand(edge_index.size(1)) < 0.85\n",
        "train_edge_index = edge_index[:, mask]\n",
        "test_edge_index = edge_index[:, ~mask]\n",
        "\n",
        "# Generate Motifs for Training\n",
        "train_motifs = get_dual_motifs(train_edge_index, num_nodes=x.size(0))\n",
        "\n",
        "print(f\"‚úÖ Motifs Generated: {train_motifs[0].size(1)} Matches, {train_motifs[1].size(1)} Cluster Edges.\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. DEFINE MGNN MODEL (NaN-Safe Version)\n",
        "# ==========================================\n",
        "class MotifConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_motifs=2):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([GCNConv(in_channels, out_channels) for _ in range(num_motifs)])\n",
        "        self.bn = nn.BatchNorm1d(out_channels) # <--- Critical for Stability\n",
        "\n",
        "    def forward(self, x, motif_graphs):\n",
        "        outs = []\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            if i < len(motif_graphs) and motif_graphs[i].size(1) > 0:\n",
        "                out = conv(x, motif_graphs[i])\n",
        "                outs.append(out)\n",
        "            else:\n",
        "                outs.append(torch.zeros(x.size(0), conv.out_channels).to(x.device))\n",
        "\n",
        "        # Sum outcomes\n",
        "        out_sum = torch.stack(outs).sum(dim=0)\n",
        "        return F.relu(self.bn(out_sum))\n",
        "\n",
        "class VibeMatchMGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        # Note: Input is already 64-dim Vibe Vector from StyleLink\n",
        "        self.mgnn1 = MotifConv(in_dim, hidden_dim)\n",
        "        self.mgnn2 = MotifConv(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, motif_graphs):\n",
        "        h = self.mgnn1(x, motif_graphs)\n",
        "        h = self.mgnn2(h, motif_graphs)\n",
        "        return h\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING LOOP\n",
        "# ==========================================\n",
        "model = VibeMatchMGNN(in_dim=64, hidden_dim=64, out_dim=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # Safe Learning Rate\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "print(f\"\\nüöÄ Training Started...\")\n",
        "print(f\"{'Epoch':<10} | {'Loss':<10} | {'Test AUC':<10}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for epoch in range(201):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 1. Forward Pass\n",
        "    z = model(x, train_motifs)\n",
        "\n",
        "    # 2. Loss Calculation\n",
        "    pos_src, pos_dst = train_edge_index\n",
        "    pos_scores = (z[pos_src] * z[pos_dst]).sum(dim=1)\n",
        "\n",
        "    neg_src, neg_dst = negative_sampling(train_edge_index, num_nodes=x.size(0))\n",
        "    neg_scores = (z[neg_src] * z[neg_dst]).sum(dim=1)\n",
        "\n",
        "    # CLAMPING: Prevent Infinity/NaN in loss\n",
        "    pos_scores = torch.clamp(pos_scores, -10, 10)\n",
        "    neg_scores = torch.clamp(neg_scores, -10, 10)\n",
        "\n",
        "    scores = torch.cat([pos_scores, neg_scores])\n",
        "    labels = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)])\n",
        "\n",
        "    loss = criterion(scores, labels)\n",
        "\n",
        "    if torch.isnan(loss):\n",
        "        print(\"‚ö†Ô∏è Loss went NaN! Skipping step.\")\n",
        "        optimizer.zero_grad()\n",
        "        continue\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # CLIPPING: Prevent Exploding Gradients\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # 3. Evaluate\n",
        "    if epoch % 20 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            z = model(x, train_motifs)\n",
        "\n",
        "            src, dst = test_edge_index\n",
        "            pos = (z[src] * z[dst]).sum(dim=1).cpu()\n",
        "            n_src, n_dst = negative_sampling(test_edge_index, num_nodes=x.size(0))\n",
        "            neg = (z[n_src] * z[n_dst]).sum(dim=1).cpu()\n",
        "\n",
        "            # Safety check for Eval NaNs\n",
        "            if torch.isnan(pos).any() or torch.isnan(neg).any():\n",
        "                auc = 0.5 # Default fallback\n",
        "            else:\n",
        "                auc = roc_auc_score(\n",
        "                    torch.cat([torch.ones_like(pos), torch.zeros_like(neg)]),\n",
        "                    torch.cat([pos, neg])\n",
        "                )\n",
        "\n",
        "            print(f\"{epoch:<10} | {loss.item():.4f}     | {auc:.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ MGNN Model Trained Successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ofact-d6e1F",
        "outputId": "8edad42b-10c6-43f2-d2bb-91957c4cc9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Setting up on cuda...\n",
            "‚úÖ Motifs Generated: 716 Matches, 2318 Cluster Edges.\n",
            "\n",
            "üöÄ Training Started...\n",
            "Epoch      | Loss       | Test AUC  \n",
            "----------------------------------------\n",
            "0          | 0.6931     | 0.5000\n",
            "20         | 0.6931     | 0.5000\n",
            "40         | 0.6931     | 0.5000\n",
            "60         | 0.6931     | 0.5000\n",
            "80         | 0.6931     | 0.5000\n",
            "100        | 0.6931     | 0.5000\n",
            "120        | 0.6931     | 0.5000\n",
            "140        | 0.6931     | 0.5000\n",
            "160        | 0.6931     | 0.5000\n",
            "180        | 0.6931     | 0.5000\n",
            "200        | 0.6931     | 0.5000\n",
            "\n",
            "‚úÖ MGNN Model Trained Successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load Data\n",
        "df = pd.read_csv('user_features.csv')\n",
        "print(f\"Data Loaded. Shape: {df.shape}\")\n",
        "\n",
        "# 2. Check Raw Features for constant columns (Variance = 0)\n",
        "# Drop IDs first\n",
        "raw_data = df.drop(columns=['user_id', 'mapped_id'], errors='ignore')\n",
        "variances = raw_data.var()\n",
        "zero_var_cols = variances[variances == 0].index.tolist()\n",
        "print(f\"Columns with Zero Variance: {len(zero_var_cols)}\")\n",
        "if len(zero_var_cols) > 0:\n",
        "    print(f\"Examples: {zero_var_cols[:5]}\")\n",
        "    # Fix: Drop them\n",
        "    raw_data = raw_data.drop(columns=zero_var_cols)\n",
        "\n",
        "# 3. Check for NaNs/Infs in Raw Data\n",
        "print(f\"NaNs in raw data: {raw_data.isna().sum().sum()}\")\n",
        "print(f\"Infs in raw data: {np.isinf(raw_data).sum().sum()}\")\n",
        "\n",
        "# 4. Normalize\n",
        "scaler = StandardScaler()\n",
        "# Note: StandardScaler handles low variance by scaling to unit variance,\n",
        "# but if var is exactly 0, it might produce 0/0 = NaN if not careful.\n",
        "# Sklearn usually handles constant cols by setting them to 0, but let's verify.\n",
        "x_scaled = scaler.fit_transform(raw_data.values)\n",
        "\n",
        "print(f\"Scaled Data Shape: {x_scaled.shape}\")\n",
        "print(f\"NaNs in Scaled Data: {np.isnan(x_scaled).sum()}\")\n",
        "print(f\"Infs in Scaled Data: {np.isinf(x_scaled).sum()}\")\n",
        "\n",
        "# 5. Run StyleLink (Encoder)\n",
        "# Recreate the exact encoder logic\n",
        "class StyleLink(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "input_dim = x_scaled.shape[1]\n",
        "model = StyleLink(input_dim, 64)\n",
        "# Initialize weights carefully (He initialization)\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    vibe_vectors = model(x_tensor)\n",
        "\n",
        "print(f\"Vibe Vectors NaNs: {torch.isnan(vibe_vectors).sum().item()}\")\n",
        "print(f\"Vibe Vectors Max: {vibe_vectors.max().item()}\")\n",
        "print(f\"Vibe Vectors Min: {vibe_vectors.min().item()}\")\n",
        "print(f\"Vibe Vectors Mean: {vibe_vectors.mean().item()}\")\n",
        "print(f\"Count of Exact Zeros: {(vibe_vectors == 0).sum().item()} / {vibe_vectors.numel()}\")\n",
        "\n",
        "# 6. Check if vectors are identical (collapsed mode)\n",
        "# Calculate standard deviation across users for feature 0\n",
        "print(f\"Std Dev across users (Feature 0): {vibe_vectors[:, 0].std().item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrd2tUwV7uTI",
        "outputId": "f45df5be-ec8f-4b68-a8e6-6a6441444cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded. Shape: (388, 388)\n",
            "Columns with Zero Variance: 0\n",
            "NaNs in raw data: 228\n",
            "Infs in raw data: 0\n",
            "Scaled Data Shape: (388, 387)\n",
            "NaNs in Scaled Data: 228\n",
            "Infs in Scaled Data: 0\n",
            "Vibe Vectors NaNs: 64\n",
            "Vibe Vectors Max: nan\n",
            "Vibe Vectors Min: nan\n",
            "Vibe Vectors Mean: nan\n",
            "Count of Exact Zeros: 12385 / 24832\n",
            "Std Dev across users (Feature 0): nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# FINAL \"VIBEMATCH\" REPAIR & TRAIN SCRIPT\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import to_undirected, negative_sampling, add_self_loops\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"üîß Starting Full Repair Pipeline...\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD & CLEAN DATA (The NaN Fix)\n",
        "# ==========================================\n",
        "df_features = pd.read_csv('user_features.csv')\n",
        "print(f\"   - Raw Data Shape: {df_features.shape}\")\n",
        "\n",
        "# Drop ID columns to isolate features\n",
        "raw_x = df_features.drop(columns=['user_id', 'mapped_id'], errors='ignore')\n",
        "\n",
        "# CRITICAL FIX: Fill NaNs with the column mean\n",
        "# This prevents the \"Input contains NaN\" error\n",
        "raw_x = raw_x.fillna(raw_x.mean())\n",
        "print(f\"   - NaNs fixed. Remaining NaNs: {raw_x.isna().sum().sum()}\")\n",
        "\n",
        "# Normalize (StandardScaler)\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(raw_x.values)\n",
        "x_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n",
        "\n",
        "# ==========================================\n",
        "# 2. RUN STYLELINK (Generate Vibe Vectors)\n",
        "# ==========================================\n",
        "class StyleLink(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim), # Stabilizes inputs\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "# Initialize and run StyleLink\n",
        "style_model = StyleLink(input_dim=x_tensor.shape[1], output_dim=64)\n",
        "style_model.eval() # Inference mode\n",
        "with torch.no_grad():\n",
        "    vibe_vectors = style_model(x_tensor)\n",
        "\n",
        "print(f\"‚úÖ Vibe Vectors Generated. Shape: {vibe_vectors.shape}\")\n",
        "print(f\"   - Vibe NaNs: {torch.isnan(vibe_vectors).sum().item()} (Should be 0)\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. BUILD GRAPH (Map Interactions)\n",
        "# ==========================================\n",
        "df_interactions = pd.read_csv('interactions_final.csv')\n",
        "\n",
        "# Create Mapping: User ID -> Index 0..N\n",
        "unique_users = df_features['user_id'].unique()\n",
        "user_map = {uid: i for i, uid in enumerate(unique_users)}\n",
        "num_nodes = len(unique_users)\n",
        "\n",
        "# Filter edges\n",
        "valid_edges = df_interactions[\n",
        "    df_interactions['source'].isin(user_map) &\n",
        "    df_interactions['target'].isin(user_map)\n",
        "].copy()\n",
        "\n",
        "src = valid_edges['source'].map(user_map).values\n",
        "dst = valid_edges['target'].map(user_map).values\n",
        "edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "\n",
        "print(f\"‚úÖ Graph Built: {num_nodes} Nodes, {edge_index.shape[1]} Edges.\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. DEFINE MGNN MODEL (No ReLU Trap)\n",
        "# ==========================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MotifConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_motifs=2, act=True):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([GCNConv(in_channels, out_channels) for _ in range(num_motifs)])\n",
        "        self.bn = nn.BatchNorm1d(out_channels)\n",
        "        self.act = act # Toggle activation\n",
        "\n",
        "    def forward(self, x, motif_graphs):\n",
        "        outs = []\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            if i < len(motif_graphs) and motif_graphs[i].size(1) > 0:\n",
        "                out = conv(x, motif_graphs[i])\n",
        "                outs.append(out)\n",
        "            else:\n",
        "                outs.append(torch.zeros(x.size(0), conv.out_channels).to(x.device))\n",
        "\n",
        "        out_sum = torch.stack(outs).sum(dim=0)\n",
        "        out = self.bn(out_sum)\n",
        "\n",
        "        # CRITICAL FIX: Only apply ReLU if act=True\n",
        "        # This prevents the \"ReLU Trap\" on the final layer\n",
        "        if self.act:\n",
        "            return F.relu(out)\n",
        "        return out\n",
        "\n",
        "class VibeMatchMGNN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        # Layer 1 (Hidden): ReLU is GOOD\n",
        "        self.mgnn1 = MotifConv(in_dim, hidden_dim, act=True)\n",
        "        # Layer 2 (Output): ReLU is BAD (Removed)\n",
        "        self.mgnn2 = MotifConv(hidden_dim, out_dim, act=False)\n",
        "\n",
        "    def forward(self, x, motif_graphs):\n",
        "        h = self.mgnn1(x, motif_graphs)\n",
        "        h = self.mgnn2(h, motif_graphs)\n",
        "        return h\n",
        "\n",
        "# ==========================================\n",
        "# 5. TRAIN LOOP\n",
        "# ==========================================\n",
        "# Prepare Data\n",
        "x = vibe_vectors.to(device)\n",
        "edge_index = edge_index.to(device)\n",
        "\n",
        "# Generate Motifs\n",
        "def get_dual_motifs(edge_index, num_nodes):\n",
        "    edge_index_safe, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
        "    row, col = edge_index\n",
        "\n",
        "    # Motif 1: Reciprocal\n",
        "    edge_set = set(zip(row.tolist(), col.tolist()))\n",
        "    recip_edges = [[u, v] for u, v in edge_set if (v, u) in edge_set]\n",
        "    motif_recip = torch.tensor(recip_edges, dtype=torch.long).t().to(device) if recip_edges else torch.empty((2, 0), dtype=torch.long).to(device)\n",
        "\n",
        "    # Motif 2: Cluster\n",
        "    motif_cluster = to_undirected(edge_index_safe).to(device)\n",
        "    return [motif_recip, motif_cluster]\n",
        "\n",
        "# Split & Motifs\n",
        "mask = torch.rand(edge_index.size(1)) < 0.85\n",
        "train_edge_index = edge_index[:, mask]\n",
        "test_edge_index = edge_index[:, ~mask]\n",
        "train_motifs = get_dual_motifs(train_edge_index, num_nodes)\n",
        "\n",
        "# Initialize Model\n",
        "model = VibeMatchMGNN(in_dim=64, hidden_dim=64, out_dim=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "print(f\"\\nüöÄ Training Started on {device}...\")\n",
        "print(f\"{'Epoch':<10} | {'Loss':<10} | {'Test AUC':<10}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for epoch in range(301):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    z = model(x, train_motifs)\n",
        "\n",
        "    # Loss\n",
        "    pos_src, pos_dst = train_edge_index\n",
        "    neg_src, neg_dst = negative_sampling(train_edge_index, num_nodes=num_nodes)\n",
        "\n",
        "    pos_scores = (z[pos_src] * z[pos_dst]).sum(dim=1)\n",
        "    neg_scores = (z[neg_src] * z[neg_dst]).sum(dim=1)\n",
        "\n",
        "    # Clamp for safety\n",
        "    pos_scores = torch.clamp(pos_scores, -10, 10)\n",
        "    neg_scores = torch.clamp(neg_scores, -10, 10)\n",
        "\n",
        "    loss = criterion(torch.cat([pos_scores, neg_scores]),\n",
        "                     torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)]))\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Eval\n",
        "    if epoch % 50 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            z = model(x, train_motifs)\n",
        "            src, dst = test_edge_index\n",
        "            pos = (z[src] * z[dst]).sum(dim=1).cpu()\n",
        "            n_src, n_dst = negative_sampling(test_edge_index, num_nodes=num_nodes)\n",
        "            neg = (z[n_src] * z[n_dst]).sum(dim=1).cpu()\n",
        "\n",
        "            auc = roc_auc_score(torch.cat([torch.ones_like(pos), torch.zeros_like(neg)]),\n",
        "                                torch.cat([pos, neg]))\n",
        "            print(f\"{epoch:<10} | {loss.item():.4f}     | {auc:.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ DONE! If AUC > 0.5, your VibeMatch Engine is alive!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tpqsWIF7u3k",
        "outputId": "936eda06-7b66-4747-bea7-a67ac9ea324f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Starting Full Repair Pipeline...\n",
            "   - Raw Data Shape: (388, 388)\n",
            "   - NaNs fixed. Remaining NaNs: 0\n",
            "‚úÖ Vibe Vectors Generated. Shape: torch.Size([388, 64])\n",
            "   - Vibe NaNs: 0 (Should be 0)\n",
            "‚úÖ Graph Built: 388 Nodes, 1585 Edges.\n",
            "\n",
            "üöÄ Training Started on cuda...\n",
            "Epoch      | Loss       | Test AUC  \n",
            "----------------------------------------\n",
            "0          | 1.3155     | 0.6730\n",
            "50         | 0.5605     | 0.8133\n",
            "100        | 0.5002     | 0.8720\n",
            "150        | 0.4710     | 0.8873\n",
            "200        | 0.4347     | 0.8684\n",
            "250        | 0.4275     | 0.8636\n",
            "300        | 0.4275     | 0.8763\n",
            "\n",
            "‚úÖ DONE! If AUC > 0.5, your VibeMatch Engine is alive!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 6. VIBEMATCH INFERENCE ENGINE\n",
        "# ==========================================\n",
        "import torch\n",
        "\n",
        "# 1. Select a Test User (Pick any ID from your data)\n",
        "# Let's pick the first user in the list\n",
        "test_user_idx = 0\n",
        "real_user_id = unique_users[test_user_idx]\n",
        "\n",
        "print(f\"üíò Generating Matches for User ID: {real_user_id}\")\n",
        "\n",
        "# 2. Get Final Embeddings from the Trained Model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Pass the features and graph through the trained MGNN\n",
        "    embeddings = model(x, train_motifs)\n",
        "\n",
        "# 3. Calculate \"Compatibility Scores\"\n",
        "# (Dot product of Test User vs Everyone Else)\n",
        "user_embedding = embeddings[test_user_idx]\n",
        "scores = (embeddings @ user_embedding).cpu().numpy()\n",
        "\n",
        "# 4. Filter Recommendations\n",
        "# We don't want to recommend people they already swiped on!\n",
        "existing_edges = edge_index[:, edge_index[0] == test_user_idx][1].cpu().numpy()\n",
        "candidates = []\n",
        "\n",
        "for other_idx in range(num_nodes):\n",
        "    # Skip self and existing connections\n",
        "    if other_idx == test_user_idx or other_idx in existing_edges:\n",
        "        continue\n",
        "\n",
        "    candidates.append((other_idx, scores[other_idx]))\n",
        "\n",
        "# 5. Sort by Vibe Score (Highest First)\n",
        "candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "top_matches = candidates[:5]\n",
        "\n",
        "# 6. Display Results\n",
        "print(f\"\\nüèÜ Top 5 Recommendations for User {real_user_id}:\")\n",
        "print(f\"{'Rank':<5} | {'User ID':<10} | {'Vibe Score':<10}\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "for rank, (idx, score) in enumerate(top_matches, 1):\n",
        "    match_id = unique_users[idx]\n",
        "    print(f\"#{rank:<4} | {match_id:<10} | {score:.4f}\")\n",
        "\n",
        "print(\"\\n(Note: A high positive score means a strong predicted match!)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obs9XAmj8tc0",
        "outputId": "58feef1e-b847-4339-e2b3-805dc01d64b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíò Generating Matches for User ID: 19\n",
            "\n",
            "üèÜ Top 5 Recommendations for User 19:\n",
            "Rank  | User ID    | Vibe Score\n",
            "-----------------------------------\n",
            "#1    | 6771       | 2.3066\n",
            "#2    | 483        | 2.2237\n",
            "#3    | 12766      | 2.1783\n",
            "#4    | 1886       | 2.0066\n",
            "#5    | 13222      | 1.8476\n",
            "\n",
            "(Note: A high positive score means a strong predicted match!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üíæ Saving VibeMatch Artifacts...\")\n",
        "\n",
        "# 1. Save the Trained Model (The Brain)\n",
        "torch.save(model.state_dict(), 'vibematch_model.pth')\n",
        "print(\"   - Model saved as 'vibematch_model.pth'\")\n",
        "\n",
        "# 2. Save the User Embeddings (The Data)\n",
        "# We run the model one last time to get the freshest vectors\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_embeddings = model(x, train_motifs)\n",
        "torch.save(final_embeddings, 'vibe_embeddings.pt')\n",
        "print(\"   - Embeddings saved as 'vibe_embeddings.pt'\")\n",
        "\n",
        "# 3. Save the Top Recommendations to CSV\n",
        "# (Assuming 'candidates' list exists from the previous step)\n",
        "rec_df = pd.DataFrame(candidates, columns=['user_idx', 'score'])\n",
        "rec_df['user_id'] = rec_df['user_idx'].map(lambda i: unique_users[i])\n",
        "rec_df = rec_df[['user_id', 'score']].head(50) # Top 50 matches\n",
        "rec_df.to_csv('top_recommendations.csv', index=False)\n",
        "print(\"   - Top 50 matches saved as 'top_recommendations.csv'\")\n",
        "\n",
        "# 4. Trigger Download (for Colab)\n",
        "print(\"\\n‚¨áÔ∏è Downloading files to your computer...\")\n",
        "files.download('vibematch_model.pth')\n",
        "files.download('vibe_embeddings.pt')\n",
        "files.download('top_recommendations.csv')"
      ],
      "metadata": {
        "id": "Z__8vscN81Gi",
        "outputId": "7c077aaf-1dc3-42ac-ee6b-7ab1f51bdeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving VibeMatch Artifacts...\n",
            "   - Model saved as 'vibematch_model.pth'\n",
            "   - Embeddings saved as 'vibe_embeddings.pt'\n",
            "   - Top 50 matches saved as 'top_recommendations.csv'\n",
            "\n",
            "‚¨áÔ∏è Downloading files to your computer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_28e1292a-9357-4a5d-a1e4-271fc4ad8683\", \"vibematch_model.pth\", 58605)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_47ee7068-b566-4740-9dcc-5c43cb232a10\", \"vibe_embeddings.pt\", 51297)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_486dd396-f34a-4d5c-953d-a88eba960279\", \"top_recommendations.csv\", 788)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}